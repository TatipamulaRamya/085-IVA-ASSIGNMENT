# -*- coding: utf-8 -*-
"""IVA_ASSIGNMENT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Za7lA2flzhPD0U8OmL_YA99FdmxbOAbS

**Sample project for Color detection**
"""

import cv2
import numpy as np
from google.colab.patches import cv2_imshow  # Use this for image display in Colab
def detect_dominant_color(image_path):
    """
    Detects the dominant color in an image using K-means clustering.
    Args:
        image_path (str): Path to the image file.
    Returns:
        tuple: (B, G, R) values of the dominant color, or None if an error occurs.
    """
    try:
        img = cv2.imread(image_path)
        if img is None:
            raise FileNotFoundError(f"Image not found at {image_path}")
        # Resize the image for faster processing
        resized_img = cv2.resize(img, (100, 100))
        # Reshape to a list of pixels
        pixels = resized_img.reshape((-1, 3))
        pixels = np.float32(pixels)
        # Apply K-means clustering
        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)
        _, _, centers = cv2.kmeans(pixels, 1, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)
        return tuple(centers[0].astype(int))
    except Exception as e:
        print(f"Error: {e}")
        return None
def display_color_swatch(color):
    """
    Displays a color swatch of the detected dominant color.
    """
    if color is None:
        print("No color detected.")
        return
    swatch = np.zeros((200, 200, 3), dtype=np.uint8)
    swatch[:] = color
    print(f"Dominant Color (BGR): {color}")
    cv2_imshow(swatch)
def detect_color_range(image_path, lower_bound, upper_bound, color_name):
    """
    Detects a specific color range in an image and highlights it.
    Args:
        image_path (str): Path to the image file.
        lower_bound (np.array): Lower HSV bound of the color.
        upper_bound (np.array): Upper HSV bound of the color.
        color_name (str): Name of the color being detected.
    """
    try:
        img = cv2.imread(image_path)
        if img is None:
            raise FileNotFoundError(f"Image not found at {image_path}")
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        mask = cv2.inRange(hsv, lower_bound, upper_bound)
        result = cv2.bitwise_and(img, img, mask=mask)
        print(f"Original Image vs {color_name} Detection:")
        combined = np.hstack((img, result))
        cv2_imshow(combined)
    except Exception as e:
        print(f"Error: {e}")
# Example usage
image_file = "Dog-Picture1.jpg"  # Replace with actual image file path
dominant_color = detect_dominant_color(image_file)
display_color_swatch(dominant_color)
# Define HSV bounds for different colors
color_ranges = {
    "Red": (np.array([0, 100, 100]), np.array([10, 255, 255])),
    "Blue": (np.array([110, 50, 50]), np.array([130, 255, 255])),
    "Green": (np.array([50, 100, 100]), np.array([70, 255, 255])),
    "Yellow": (np.array([20, 100, 100]), np.array([30, 255, 255])),
    "Orange": (np.array([10, 100, 100]), np.array([20, 255, 255])),
    "Purple": (np.array([130, 50, 50]), np.array([160, 255, 255])),
    "White": (np.array([0, 0, 200]), np.array([180, 50, 255]))
}
for color_name, (lower, upper) in color_ranges.items():
    detect_color_range(image_file, lower, upper, color_name)

"""**Data structures for Image Analysis -Write a program that
computes the T-pyramid of an image**
"""

import cv2
import numpy as np
from google.colab.patches import cv2_imshow  # Use for displaying images in Colab
def t_pyramid(image, levels):
    """
    Computes the T-pyramid of an image.
    Args:
        image (numpy.ndarray): Input image.
        levels (int): Number of pyramid levels.
    Returns:
        list: List of pyramid levels (images).
    """
    pyramid = [image.astype(np.float32)]  # Convert to float32 for calculations
    for _ in range(levels - 1):
        # Apply a 5x5 Gaussian filter and downsample by 2
        blurred = cv2.GaussianBlur(pyramid[-1], (5, 5), 0)
        downsampled = blurred[::2, ::2]
        pyramid.append(downsampled)
    return pyramid
def display_pyramid(pyramid):
    """
    Displays the T-pyramid levels in Google Colab at their actual sizes.
    Args:
        pyramid (list): List of pyramid levels (images).
    """
    for i, level in enumerate(pyramid):
        normalized_level = cv2.normalize(level, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)
        print(f"Level {i}:")
        cv2_imshow(normalized_level)  # Display without resizing
# Example usage:
image_path = "solarsystem.jpg"  # Replace with your image path
image = cv2.imread(image_path)
if image is None:
    print(f"Error: Image not found at {image_path}")
else:
    pyramid_levels = 5  # Number of pyramid levels
    pyramid = t_pyramid(image, pyramid_levels)
    display_pyramid(pyramid)

"""**Sample project for Image Smoothing**"""

import cv2
import numpy as np
from google.colab.patches import cv2_imshow  # Use this instead of cv2.imshow
def image_smoothing(image_path):
    """
    Applies various image smoothing techniques to an image and displays them side by side.
    Args:
        image_path (str): Path to the image file.
    """
    try:
        img = cv2.imread(image_path)
        if img is None:
            raise FileNotFoundError(f"Image not found at {image_path}")
        # 1. Averaging (Blur)
        blur = cv2.blur(img, (5, 5))
        # 2. Gaussian Blur
        gaussian_blur = cv2.GaussianBlur(img, (5, 5), 0)
        # 3. Median Blur (Effective for salt-and-pepper noise)
        median_blur = cv2.medianBlur(img, 5)
        # 4. Bilateral Filtering (Preserves edges)
        bilateral_blur = cv2.bilateralFilter(img, 9, 75, 75)
        # Concatenating images side by side for better visualization
        avg_stack = np.hstack((img, blur))
        gaussian_stack = np.hstack((img, gaussian_blur))
        median_stack = np.hstack((img, median_blur))
        bilateral_stack = np.hstack((img, bilateral_blur))
        # Display results using cv2_imshow
        print("Original (Left) | Averaging Blur (Right):")
        cv2_imshow(avg_stack)
        print("Original (Left) | Gaussian Blur (Right):")
        cv2_imshow(gaussian_stack)
        print("Original (Left) | Median Blur (Right):")
        cv2_imshow(median_stack)
        print("Original (Left) | Bilateral Filter (Right):")
        cv2_imshow(bilateral_stack)
    except Exception as e:
        print(f"Error: {e}")
# Example usage:
image_file = "chinnu.jpg"  # Replace with your image file path
image_smoothing(image_file)

"""**Sample project for Edge detection using Sobel ,Canny edge**"""

import cv2
import numpy as np
from google.colab.patches import cv2_imshow  # Use this instead of cv2.imshow
def edge_detection(image_path, kernel_size=3):
    """
    Applies Sobel and Canny edge detection to an image and displays
    the original, Sobel, and Canny images side by side.
    Args:
        image_path (str): Path to the image file.
        kernel_size (int): Kernel size for Sobel edge detection (default is 3).
    """
    try:
        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Load in grayscale
        if img is None:
            raise FileNotFoundError(f"Image not found at {image_path}")
        # Sobel Edge Detection
        sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=kernel_size)  # Sobel in x-direction
        sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=kernel_size)  # Sobel in y-direction
        sobel_combined = np.sqrt(sobelx**2 + sobely**2)  # Combine x and y gradients
        sobel_combined = np.uint8(sobel_combined)  # Convert back to 8-bit
        # Canny Edge Detection
        canny = cv2.Canny(img, 100, 200)  # Thresholds: 100 and 200 (adjust as needed)
        # Stack images side by side (Original | Sobel | Canny)
        combined = cv2.hconcat([img, sobel_combined, canny])
        # Display results
        print(f"Original | Sobel | Canny (Kernel Size {kernel_size}):")
        cv2_imshow(combined)
    except Exception as e:
        print(f"Error: {e}")
# Example usage:
image_file = "flower_img.jpg"  # Replace with your image file path
edge_detection(image_file, 3)  # Kernel size 3
edge_detection(image_file, 5)  # Kernel size 5

"""**Object Detection with OpenCV**
* **Detect simple objects like faces, eyes, or hands using OpenCV and Haar cascade**
* **Libraries: OpenCV, NumPy**





"""

import cv2
import matplotlib.pyplot as plt
import numpy as np
# Load Haar cascade classifiers
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')
smile_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_smile.xml')
# Read the image
image_path = 'chandhu_img.jpg'
image = cv2.imread(image_path)
if image is None:
    print("Error: Image not found!")
    exit()
# Convert image to grayscale
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
# Detect faces
faces = face_cascade.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=6, minSize=(50, 50))
for (x, y, w, h) in faces:
    # Draw face rectangle with gradient blue effect
    cv2.rectangle(image, (x, y), (x + w, y + h), (30, 144, 255), 5)
    cv2.rectangle(image, (x + 3, y + 3), (x + w - 3, y + h - 3), (0, 0, 255), 2)
    cv2.putText(image, 'Face', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 3)
    # Define ROI for eyes and smile detection
    roi_gray = gray[y:y + h, x:x + w]
    roi_color = image[y:y + h, x:x + w]
    # Detect eyes
    eyes = eye_cascade.detectMultiScale(roi_gray, scaleFactor=1.1, minNeighbors=5, minSize=(20, 20))
    for (ex, ey, ew, eh) in eyes:
        cv2.rectangle(roi_color, (ex, ey), (ex + ew, ey + eh), (50, 205, 50), 3)  # Bright green
        cv2.putText(roi_color, 'Eye', (ex, ey - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
    # Detect smiles
    smiles = smile_cascade.detectMultiScale(roi_gray, scaleFactor=1.8, minNeighbors=25, minSize=(25, 25))
    for (sx, sy, sw, sh) in smiles:
        cv2.rectangle(roi_color, (sx, sy), (sx + sw, sy + sh), (255, 140, 0), 3)  # Vivid orange
        cv2.putText(roi_color, 'Smile', (sx, sy - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
    # Hair Detection: Region above the face
    hair_region_y = max(0, y - h // 2)  # Define hair region above the face
    hair_region = gray[hair_region_y:y, x:x + w]  # Crop above the face
    # Apply edge detection to highlight hair
    hair_edges = cv2.Canny(hair_region, 50, 150)
    # Draw a rectangle for the hair region
    cv2.rectangle(image, (x, hair_region_y), (x + w, y), (128, 0, 128), 3)  # Royal purple
    cv2.putText(image, 'Hair', (x, hair_region_y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
# Convert image to RGB for Matplotlib
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
# Display image with enhancements
plt.figure(figsize=(10, 8))
plt.imshow(image_rgb)
plt.axis("off")
plt.suptitle("Face, Eyes, Smile & Hair Detection", fontsize=16, fontweight='bold', color='purple')
plt.title("Using OpenCV & Haar Cascades", fontsize=12, fontweight='medium', color='black')
plt.show()